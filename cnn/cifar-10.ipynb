{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=7\n",
    "numpy.random.seed(SEED)\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    (X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "\n",
    "    Y_train = np_utils.to_categorical(Y_train)\n",
    "    Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "    data = {}\n",
    "    data['input_dim'] = numpy.shape(X_train[0,:])\n",
    "    data['train'] = (X_train, Y_train)\n",
    "    data['test'] = (X_test, Y_test)\n",
    "    data['num_outputs'] = len(Y_train[0])\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_dim, output_dim, learning_rate=0.1, decay=0.01):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Extract initial feature maps\n",
    "    model.add(Conv2D(32, (3,3), input_shape=input_dim, kernel_initializer='normal', padding='same', \n",
    "                     activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    # add additional non linearity\n",
    "    model.add(Conv2D(32, (3,3), kernel_initializer='normal', padding='same', \n",
    "                     activation='relu'))\n",
    "    # Reduce Spatial Dimnesion\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # 64 Feature Maps\n",
    "    model.add(Conv2D(64, (3,3), kernel_initializer='normal', padding='same', \n",
    "                     activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    # 64 Feature Maps + additional non linearity\n",
    "    model.add(Conv2D(64, (3,3), kernel_initializer='normal', padding='same', \n",
    "                     activation='relu'))\n",
    "    # Reduce Spatial Dimnesion\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # 128 Feature maps\n",
    "    model.add(Conv2D(128, (3,3), kernel_initializer='normal', padding='same', \n",
    "                     activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (3,3), kernel_initializer='normal', padding='same', \n",
    "                     activation='relu'))\n",
    "    # Reduce Spatial Dimnesion\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    # Prepare for FC\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "    sgd = SGD(lr=learning_rate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-6-b7fb479e993e>(18)load_data()\n",
      "-> data = {}\n",
      "(Pdb) c\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "\n",
      "Program interrupted. (Use 'cont' to resume).\n",
      "--Call--\n",
      "> /Users/Gunners/anaconda3/envs/py3/lib/python3.6/contextlib.py(85)__exit__()\n",
      "-> def __exit__(self, type, value, traceback):\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = load_data()\n",
    "epochs = 50\n",
    "lr = 0.01\n",
    "decay = (lr * 2)/epochs\n",
    "\n",
    "cnn = create_model(data['input_dim'], data['num_outputs'], lr, decay)\n",
    "\n",
    "history = cnn.fit(data['train'][0], data['train'][1], validation_data=(data['test']),\n",
    "                  epochs=epochs, batch_size=64, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
